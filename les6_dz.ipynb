{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd34fdf",
   "metadata": {},
   "source": [
    "## Тема “Обучение с учителем”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff755186",
   "metadata": {},
   "source": [
    "#### Задание 1\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.\n",
    "\n",
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b87393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b11d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  price  \n",
       "0       15.3  396.90   4.98   24.0  \n",
       "1       17.8  396.90   9.14   21.6  \n",
       "2       17.8  392.83   4.03   34.7  \n",
       "3       18.7  394.63   2.94   33.4  \n",
       "4       18.7  396.90   5.33   36.2  \n",
       "..       ...     ...    ...    ...  \n",
       "501     21.0  391.99   9.67   22.4  \n",
       "502     21.0  396.90   9.08   20.6  \n",
       "503     21.0  396.90   5.64   23.9  \n",
       "504     21.0  393.45   6.48   22.0  \n",
       "505     21.0  396.90   7.88   11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "data = boston[\"data\"]\n",
    "feature_names = boston[\"feature_names\"]\n",
    "target = boston[\"target\"]\n",
    "\n",
    "X = pd.DataFrame(data, columns=feature_names)\n",
    "y = pd.DataFrame(target, columns=[\"price\"])\n",
    "\n",
    "pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15ecc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c33b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b6395c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112260057484973"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc9dc4f",
   "metadata": {},
   "source": [
    "#### Задание 2\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble. Сделайте агрумент n_estimators равным 1000, max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0], чтобы получить из датафрейма одномерный массив Numpy, так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce4d9370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71235ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=12, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)\n",
    "model.fit(X_train, y_train.values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a808f7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87472606157312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rfr = model.predict(X_test)\n",
    "r2_score(y_test, y_pred_rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4fd8cf",
   "metadata": {},
   "source": [
    "В данном случае модель, использующая Random Forest Regressor, работает лучше. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ee398",
   "metadata": {},
   "source": [
    "#### *Задание 3\n",
    "\n",
    "Вызовите документацию для класса RandomForestRegressor, найдите информацию об атрибуте feature_importances_.\n",
    "\n",
    "С помощью этого атрибута найдите сумму всех показателей важности, установите, какие два признака показывают наибольшую важность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72421f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "feature_importances.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08f90672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importances = pd.Series(feature_importances, feature_names)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "feature_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Важность признаков\")\n",
    "ax.set_ylabel('Важность')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f79f83",
   "metadata": {},
   "source": [
    "Два наиболее важных признака: RM - average number of rooms per dwelling, LSTAT - % lower status of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b415e583",
   "metadata": {},
   "source": [
    "#### *Задание 4\n",
    "\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "\n",
    "1. Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "2. Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "3. С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована. Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма: pd.options.display.max_columns = 100.\n",
    "4. Просмотрите первые 10 строк датафрейма df.\n",
    "5. Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "6. Создайте объект Series под названием y из столбца Class.\n",
    "7. Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y. У вас должны получиться объекты X_train, X_test, y_train и y_test. Просмотрите информацию о их форме.\n",
    "8. Для поиска по сетке параметров задайте такие параметры:\n",
    "- parameters = \\[{'n_estimators': \\[10, 15\\],\n",
    "- 'max_features': np.arange(3, 5),\n",
    "- 'max_depth': np.arange(4, 7)}\\]\n",
    "9. Создайте модель GridSearchCV со следующими аргументами:\n",
    "- estimator=RandomForestClassifier(random_state=100),\n",
    "- param_grid=parameters,\n",
    "- scoring='roc_auc',\n",
    "- cv=3.\n",
    "10. Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "11. Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "12. Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "13. Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "14. Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a0bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b1fda85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('..\\les4\\creditcard.csv')\n",
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc97dac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7c819da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d8431d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a209e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e5e0daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199364, 30)\n",
      "(85443, 30)\n",
      "(199364,)\n",
      "(85443,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd0d4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [10, 15],\n",
    "    'max_features': np.arange(3, 5),\n",
    "    'max_depth': np.arange(4, 7),\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=100),\n",
    "    param_grid=parameters,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ec2cb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n",
       "             param_grid={'max_depth': array([4, 5, 6]),\n",
       "                         'max_features': array([3, 4]),\n",
       "                         'n_estimators': [10, 15]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26fd96b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d69233a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_depth=6, max_features=3, n_estimators=15)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45d7c256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00052218, 0.00033805, 0.00031521, ..., 0.00031521, 0.00037104,\n",
       "       0.07461633])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = y_pred[:, 1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15d5c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7baa1132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9480539320609078"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
